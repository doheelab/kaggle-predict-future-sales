{"cells":[{"cell_type":"markdown","source":["<h2>Let's Start<h2>"],"metadata":{"_uuid":"203fec945d3518c53f50cc1952b9876722576dbf"}},{"cell_type":"markdown","source":["Lets first discuss what we are given and what we have to predict.\n","About our dataset :\n","\n","We have in our training data :- \n","1. date - every date of items sold\n","2. date_block_num - this number given to every month\n","3. shop_id - unique number of every shop\n","4. item_id - unique number of every item\n","5. item_price - price of every item\n","6. item_cnt_day - number of items sold on a particular day \n","\n","We have in our testing data :- \n","1. ID - unique for every (shop_id,item_id) pair.\n","2. shop_id - unique number of every shop\n","3. item_id - unique number of every item\n","\n","Now what we have to predict ?\n","we have to predict how many items of a type from each shop  will be sold in a whole month.\n","Our submission should have ID and item_cnt_month columns.\n","\n","What is our approach?\n","our approach will be simple.\n","Our features will be number of items sold in month from a shop excluding last month data because that will our labels, that we help our model learn to predict next sequence. And for testing will use number of items sold in month from a shop excluding first month like this dimension of our data remains same. Our model will predict the next sequence and that we will be our results. This is pretty simple approach but its good for start. Please try some different approaches also. \n","And please let me know if I did something wrong. If you like it please vote it up.\n"],"metadata":{"_uuid":"7e5b13f63519b7d38eaac0c06ffd5793e0a43eab"}},{"cell_type":"markdown","source":["<h3>I would appreciate if you could upvote this kernel.<h3>"],"metadata":{}},{"cell_type":"markdown","source":["First of all as we know import required libraries"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\r\n","import pandas as pd \r\n","import os"],"outputs":[],"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true}},{"cell_type":"code","execution_count":null,"source":["#loading data \r\n","os.listdir('../input')\r\n","sales_data = pd.read_csv('../input/sales_train.csv')\r\n","item_cat = pd.read_csv('../input/item_categories.csv')\r\n","items = pd.read_csv('../input/items.csv')\r\n","shops = pd.read_csv('../input/shops.csv')\r\n","sample_submission = pd.read_csv('../input/sample_submission.csv')\r\n","test_data = pd.read_csv('../input/test.csv')\r\n"],"outputs":[],"metadata":{"trusted":true,"_uuid":"f63e065519f029cfc2c0e9580fb2e95a146ef0d5"}},{"cell_type":"code","execution_count":null,"source":["def basic_eda(df):\n","    print(\"----------TOP 5 RECORDS--------\")\n","    print(df.head(5))\n","    print(\"----------INFO-----------------\")\n","    print(df.info())\n","    print(\"----------Describe-------------\")\n","    print(df.describe())\n","    print(\"----------Columns--------------\")\n","    print(df.columns)\n","    print(\"----------Data Types-----------\")\n","    print(df.dtypes)\n","    print(\"-------Missing Values----------\")\n","    print(df.isnull().sum())\n","    print(\"-------NULL values-------------\")\n","    print(df.isna().sum())\n","    print(\"-----Shape Of Data-------------\")\n","    print(df.shape)\n","    \n","    "],"outputs":[],"metadata":{"trusted":true,"_uuid":"4f01c334c611aa85639105835ae6c12968e5f9ab"}},{"cell_type":"code","execution_count":null,"source":["#Litle bit of exploration of data\n","\n","print(\"=============================Sales Data=============================\")\n","basic_eda(sales_data)\n","print(\"=============================Test data=============================\")\n","basic_eda(test_data)\n","print(\"=============================Item Categories=============================\")\n","basic_eda(item_cat)\n","print(\"=============================Items=============================\")\n","basic_eda(items)\n","print(\"=============================Shops=============================\")\n","basic_eda(shops)\n","print(\"=============================Sample Submission=============================\")\n","basic_eda(sample_submission)\n","\n"],"outputs":[],"metadata":{"trusted":true,"_uuid":"40841bde3a83799519bf695f361a62fe03d9e4f1"}},{"cell_type":"code","execution_count":null,"source":["#we can see that 'date' column in sales_data is an object but if we want to manipulate \n","#it or want to work on it someway then we have convert it on datetime format\n","sales_data['date'] = pd.to_datetime(sales_data['date'],format = '%d.%m.%Y')"],"outputs":[],"metadata":{"trusted":true,"_uuid":"aa425faed80de06ea817c0bab179e47e33a1aa57"}},{"cell_type":"code","execution_count":null,"source":["#now we will create a pivot tabel by going so we get our data in desired form \n","#we want get total count value of an item over the whole month for a shop \n","# That why we made shop_id and item_id our indices and date_block_num our column \n","# the value we want is item_cnt_day and used sum as aggregating function \n","dataset = sales_data.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')\n"],"outputs":[],"metadata":{"trusted":true,"_uuid":"0f919596e10dd4adafb8825f2c0d42b8c8ddd07a"}},{"cell_type":"code","execution_count":null,"source":["# lets reset our indices, so that data should be in way we can easily manipulate\n","dataset.reset_index(inplace = True)"],"outputs":[],"metadata":{"trusted":true,"_uuid":"2ab7ea5328f337d2d90477215045bcdd5b3a289c"}},{"cell_type":"code","execution_count":null,"source":["# lets check on our pivot table\n","dataset.head()"],"outputs":[],"metadata":{"trusted":true,"_uuid":"efe0d2b799958be1ed8273ff21b641659671036b"}},{"cell_type":"code","execution_count":null,"source":["# Now we will merge our pivot table with the test_data because we want to keep the data of items we have\n","# predict\n","dataset = pd.merge(test_data,dataset,on = ['item_id','shop_id'],how = 'left')"],"outputs":[],"metadata":{"trusted":true,"_uuid":"6d3f8cddfa21cd9b07ba1f6d6f243632050a3d07"}},{"cell_type":"code","execution_count":null,"source":["# lets fill all NaN values with 0\n","dataset.fillna(0,inplace = True)\n","# lets check our data now \n","dataset.head()"],"outputs":[],"metadata":{"trusted":true,"_uuid":"5e8e4c20cdeda9487557f5570461358d919bab72"}},{"cell_type":"code","execution_count":null,"source":["# we will drop shop_id and item_id because we do not need them\n","# we are teaching our model how to generate the next sequence \n","dataset.drop(['shop_id','item_id','ID'],inplace = True, axis = 1)\n","dataset.head()"],"outputs":[],"metadata":{"trusted":true,"_uuid":"1e16316986055e62840caf762d2dc0cde3e49271"}},{"cell_type":"code","execution_count":null,"source":["# X we will keep all columns execpt the last one \n","X_train = np.expand_dims(dataset.values[:,:-1],axis = 2)\n","# the last column is our label\n","y_train = dataset.values[:,-1:]\n","\n","# for test we keep all the columns execpt the first one\n","X_test = np.expand_dims(dataset.values[:,1:],axis = 2)\n","\n","# lets have a look on the shape \n","print(X_train.shape,y_train.shape,X_test.shape)\n"],"outputs":[],"metadata":{"trusted":true,"_uuid":"dc7ca752bc9f265b71861a72499aec3dbcc28dfb"}},{"cell_type":"code","execution_count":null,"source":["# importing libraries required for our model\n","from keras.models import Sequential\n","from keras.layers import LSTM,Dense,Dropout"],"outputs":[],"metadata":{"trusted":true,"_uuid":"dba3a0a291adce5f2146455fdb670996224aad70"}},{"cell_type":"code","execution_count":null,"source":["# our defining our model \n","my_model = Sequential()\n","my_model.add(LSTM(units = 64,input_shape = (33,1)))\n","my_model.add(Dropout(0.4))\n","my_model.add(Dense(1))\n","\n","my_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\n","my_model.summary()\n"],"outputs":[],"metadata":{"trusted":true,"_uuid":"c6c04c796d4b30f7330d97ede3cdca92a7607a4c"}},{"cell_type":"code","execution_count":null,"source":["my_model.fit(X_train,y_train,batch_size = 4096,epochs = 10)"],"outputs":[],"metadata":{"trusted":true,"_uuid":"a25822391ef2ab412f5abdd2b317d9eec825e19b","scrolled":true}},{"cell_type":"code","execution_count":null,"source":["# creating submission file \n","submission_pfs = my_model.predict(X_test)\n","# we will keep every value between 0 and 20\n","submission_pfs = submission_pfs.clip(0,20)\n","# creating dataframe with required columns \n","submission = pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n","# creating csv file from dataframe\n","submission.to_csv('sub_pfs.csv',index = False)\n"],"outputs":[],"metadata":{"trusted":true,"_uuid":"ab9760e02619d6a3d408e0d4f427adc1f20504c2"}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('pyupbit': conda)"},"language_info":{"name":"python","version":"3.8.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"8d4ffec1ba7bfee5fde9416519399d62d37f78eef7038bf1f142afdde7564a5c"}},"nbformat":4,"nbformat_minor":1}